---
title: 关于模型优化的几个思考-如何做模型调优
---

## {{page.title}}

<p class="meta">15 Feb 2020</p>


进入模型的优化阶段就好似进入了一个瓶颈期，在这个阶段模型的同学一直在调数据跑模型，但见效甚微，大家难免会有些感到手足无措，或者沮丧，这种情况在咱们做模型的过程中肯定会经常遇到的。那么如果碰到这种情况了，我们应该如何去进一步实现我们的目标，体现我们作为算法的价值呢？我觉得有几个点可以和大家分享下看法。

首先，定位问题。对于算法建模来说，我们的目标不是为了找到最好的模型，最先进的模型，而是用模型加数据来构建我们对目标的认识。模型在这个过程中起到的作用是生产工具，是实现手段，是网；而数据在这个过程中是生产原料，是池塘。结合我们的优化问题，我们看到的现象是模型效果不好，那么从咱们数据和模型的角度来看，导致模型不好的原因有哪些？这个是需要我们仔细考量的。我先抛砖引玉，提几个关于效果不好方面的问题：
	- a)从模型角度来说，我们当前的模型假设是什么？模型表达能力够么？还是太复杂了？模型能够快速迭代么？
	- b)从模型和数据结合来说，对结果不好的数据，为什么学不好？模型学到的是数据中的哪部分信息？模型是欠拟合还是过拟合？如果是过拟合，那么结合模型来看，我们有什么泛化调优手段，删掉一些数据能解决不？如果是欠拟合，我们如何扩充数据？
	- c)从数据角度。我们的数据哪些是期望模型可以学到的？什么样的数据，什么规模的数据，模型是可以学习的？我们对于数据的认识是什么？通过模型对数据的认识是什么？数据是均衡的么？数据是干净的么？

其次，排优先次序。在确定了我们的效果由不同维度的原因造成后，我们该如何做呢？一股脑乱炖？肯定不行，这里面首先要分清楚哪些对我们的目标来说影响范围的是如何的。这个影响范围在界定的时候一定要有一个链路反馈到最终结果上，这个链路我们得清晰。比如我们在预测结果上看到某类badcase，那么这类badcase的规模如何？这类badcase是如何出现的，对我们的模型指标的影响是多少？如何评估？badcase是模型效果不好的直接展现，那么这个到底是由模型还是数据造成的？由模型的哪些方面影响的？由哪些数据导致的？这些得我们通过数据分析确定，最终形成我们对于效果不好这个宏观问题的深入认识。

最后，解决方案。作为算法建模同学，最近这两年NLP领域发展迅猛，各种新模型百花齐放，ELMo，BERT，AlBERT等等，根本不给人喘息的机会。我相信大家在每次碰到新算法模型出现的时候是兴奋的。说实话，我是既焦虑又兴奋的。兴奋的是学术界对于NLP的难点问题又有了新的进展，我们又了“新锄头”，焦虑的是不知道自己什么时候有时间来掌握这个“新锄头”的用法。但是对于新模型的尝试在我们实际业务场景下的运用，是要结合我们的问题和目标来的。对于模型的认知咱们要有个相对的评估。学术界的模型是为了在最好的模型上再往前走，是登山，而我们是在业务场景落地，更像是修路。我们不用只要是能让我们的业务数据价值通过充分发挥出来，就够了。学术界的标准集是标准的，业务的标准集是一坨的。上面说那么多，其实简单来说，就是要多从数据出发选模型，从快速解决可解问题出发选模型。另外，在模型组合方案上，我们可以多做试错。Boosting，Bagging，甚至强化学习，可以是单一模型，但是我们可不可以把这些思想用在我们的模型组合方案上呢？模型不是万能的。业务落地的时候一定是在解决方案上要做些设计的。模型是对数据的抽象，规则也是的(正则也算)，也是模型的一种形式。我们本质上在用高效的工具对数据进行抽象组织的。所以对于选择工具上可以不用局限自己。我们的核心价值在于用模型作为杠杆来撬动需要大量人力或者人力不可解的数据问题的。

整体来说，模型优化是不管做什么业务问题，都会碰到的，对我们来说，我们只需要在我们的业务场景下解决业务问题就行。
