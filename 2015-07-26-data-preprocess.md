---
title: ML－DataPreprocess
date: 2015-07-26 00:00:00 Z
layout: post
---

{{ page.title }}
=========
<p class="meta" >26 July 2015</p>

最近在做购物人群的预测问题。具体的问题描述是根据淘宝店铺用户历史的浏览，下单，购买行为
预测出在下一段时间购买用，可以看作简单的二分类问题。找到这批用户后对其进行广告投放，提高广告主投放受益。接下来主要从两个方面来简单
总结下，一个是建模时遇到的问题，另外一个是对业务的理解上。

#### 1. 人群购买预测模型特征构建相关

在任务确定的时候，首先确定了下问题的定义以及可能用到的特征，正负样本的定义，训练和测试数据的选取。
在[Tan](http://www.amazon.com/Introduction-Data-Mining-1st-first/dp/B006UTDDJU/ref=mt_hardcover?_encoding=UTF8&me=)
的书中第一章提到了数据的基本类型，总体分为两大类，Categorical和Numeric。其中前者又可分为两类Nominal,Ordinal;后者
分为Interval,Ratio。换种比较通俗的说法就是把特征分为定性的和定量的两种。定性的特征一般的描述的是对象的特异性(Distinctness)，
有序性(Order)，对应的特征类型是Nominal和Ordinal。定量的特征一半描述的是对象的加减,乘除,对应的特征类型是Interval,Ratio。

对于人群购买预测模型来说，基本的对象就是一个人，描述的维度主要是行为，其实也可以将这个人的其他维度信息加进来，如性别，
职业等。而行为这个维度又分为三种基本的行为。因为是通过用户的历史行为来预测未来一段时间内的行为，所以这里面还有一个隐含
的限制维度就是时间。历史行为的时间段也是影响问题的一个因素。综合以上因素构建人群特征，主要从以下几个方面。对于每种行为来说，
在不同时间片上，构建该行为的Binary特征表示是否发生过该行为，统计行为频次，行为频次与其他行为频次的比值，各个行为的发生与否
行为模式特征，另外结合每种行为的特点构建描述每种行为质量的特征，如浏览行为中浏览质量数值化浏览深度，浏览黏度，连续浏览天数
等。只有把这些深层次的特征挖掘出来，才能真正较好的去描述刻画这种行为，进而准确的描述一个人。

总的来说，构建特征的过程一定要不断的深化建立对描述对象全面的认识。特征构建的好坏对模型效果有着决定性的影响，决定了模型
效果的上限。

#### 2. 训练和测试数据集的选择

数据倾斜(Skewed data)的情况主要是因为实际上很多人会看了不买的，那么这时候整体样本就会倾斜。数据倾斜一般的处理方法都是
通过采样(Sampling)来调整的。Tan在书中也说了采样，但是并没有说出采样到底能解决什么问题，只是说了全集数据处理代价大这个方面。
在这些家伙的[研究](https://www3.nd.edu/~dial/papers/SPRINGER05.pdf)说了些解决策略，不管抽样方法多么翻来覆去，至少证明了
一点，抽样方法对解决问题是有用滴。在这儿因为数据的倾斜的比例大概1:20，正样本的量还好，所以我主要侧重于负样本的抽样。
现阶段主要用随机无放回来调整正负比例，发现比例在1:15的时候模型效果最好。通过抽样方法的调试，我觉得这个样本量的差异
其实核心影响的是数据覆盖面的一个问题，另外可能影响的因素是模型对正负样本特征权重偏好的问题。

在刚开始构建模型的时候，对于训练集测试集的构建过程有个问题，就是样本选取范围的问题，有三种数据集构建策略:

- a.选取m1,m2两个月的行为数据作为训练数据，在m1,m2两个月有购买的作为正样本，其余的作为负样本构建训练集；选取m3
  数据作为测试集，m3种有购买的正样本，其他作为负样本
- b.选取m1, m2作为训练数据，m3有购买的做正样本，m3未购买的作为负样本，构建训练集；测试集合也是以m2,m3的作为特征
  构建数据，以m4月份的用户区分正负样本
- c.选取m1, m2构建特征，m3有购买的做正样本，m3未购买的作为负样本，用数据的2/3构建训练集，1/3作为测试集。

这三种数据集合的构建方式第一种问题最大，在训练数据和测试数据的一致性上没有很好的把握时间的特性。后两种还好。


#### 3. 关于模型训练

目前主要是训练了逻辑回归模型，以及GBDT。模型的调试Andrew Ng有个很好的调试的建议[ppt](http://cs229.stanford.edu/materials/ML-advice.pdf)，非常值得看看。模型结果不好无非overfit,underfit。在ppt中也建议了解决方法。这里主要说说我自己对模型调试的方法。

对于逻辑回归模型(LR)出现过拟合的情况，通过调试发现影响对大的是不同正则化方法的选择，L1正则化对特征选择的效果比L2明显。
GBDT模型平均效果要好于LR, 主要是抗过拟合能力很显著。但是就是训练速度比LR慢。

#### 小结

周五的时候被Xu拉去谈了很久。每次总是跑不了说我做事慢。我都无奈了。在工作上还是要注意工作方法。
简单来说，接到任务后，先花费两天做出一个最粗糙的结果，然后将结果反馈，病描述自己解决的问题的对象，这个过程是
对问题的定义及确认阶段，同时也是对任务难度的估计阶段。而后确定接下来任务的方向与难度，时间规划。要及时反馈。

关于GBDT，这两几篇篇博文
[B1](http://blog.csdn.net/w28971023/article/details/8240756),
[B2](http://www.52ml.net/15084.html),
[B3](http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/random-forest-and-gbdt.html),
[B4](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/02/machine-learning-boosting-and-gradient-boosting.html)
挺好的。

以后要继续坚持锻炼身体。
